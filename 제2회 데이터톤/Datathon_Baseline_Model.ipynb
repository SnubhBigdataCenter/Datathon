{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6f3f60c9",
      "metadata": {
        "id": "6f3f60c9"
      },
      "source": [
        "# 다음 안내를 반드시 따라주시기 바랍니다.\n",
        "- 메일로 할당받은 GPU 번호를 반드시 입력바랍니다.\n",
        "- 새로 만드시는 jupyter file에도 아래의 셀(GPU지정 코드, 메모리 제한 코드)를 복사하여 실행 바랍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f422626",
      "metadata": {
        "id": "0f422626"
      },
      "outputs": [],
      "source": [
        "# gpu 지정\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='3' #tensorflow log level 제한\n",
        "os.environ['CUDA_VISIBLE_DEVICES']=\"메일로 할당받은 GPU 번호\" # ← 여기에 메일로 할당받은 gpu 번호를 입력바랍니다\n",
        "## 입력예시)   os.environ['CUDA_VISIBLE_DEVICES']=\"100\"\n",
        "\n",
        "\n",
        "# gpu 메모리 제한\n",
        "import tensorflow as tf\n",
        "gpus=tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try: tf.config.experimental.set_virtual_device_configuration(gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=16225)])\n",
        "    except RuntimeError as e: print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e04439f",
      "metadata": {
        "id": "7e04439f"
      },
      "outputs": [],
      "source": [
        "## 1. Data input\n",
        "\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "import glob\n",
        "import pickle\n",
        "from PIL import Image\n",
        "from time import time\n",
        "\n",
        "# Table\n",
        "datathon_raw=pd.read_csv('dataset/datathon_train/datathon_train.csv', sep=',', encoding='utf-8-sig')\n",
        "\n",
        "# Image - meta table\n",
        "img_meta_raw=pd.read_csv('dataset/datathon_train/datathon_train_metadata.csv', sep=',')\n",
        "\n",
        "# Image - file\n",
        "img_raw=glob.glob('dataset/datathon_train/datathon_train_image/*.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1255f748",
      "metadata": {
        "id": "1255f748"
      },
      "outputs": [],
      "source": [
        "## 2. Table 전처리\n",
        "\n",
        "# OUTCOME이 .2인 값 인덱스 확인 및 제거\n",
        "outcome_2=datathon_raw[datathon_raw['OUTCOME']==2].index\n",
        "datathon=datathon_raw.drop(outcome_2, inplace=False)\n",
        "\n",
        "# 컬럼 이름 및 값 수정\n",
        "datathon=datathon.rename(columns={'초기산소\\n요구도':'init_oxy',\n",
        "                        'ESRD\\n(HD여부)':'ESRD',\n",
        "                        '고형암(C':'solidcancer',\n",
        "                        '혈액암(D)':'bloodcancer',\n",
        "                        '천식':'asthma',\n",
        "                        'eGFR-Schwartz(소아)':'eGFR-Schwartz'})\n",
        "\n",
        "datathon=datathon.replace({'20대' : '20_age', '30대' : '30_age',\n",
        "                           '40대' : '40_age', '50대' : '50_age',\n",
        "                           '60대' : '60_age', '70대' : '70_age',\n",
        "                           '80대' : '80_age', '90세 이상' : '90_age'})\n",
        "\n",
        "# One-Hot encoding\n",
        "sex_feature=pd.get_dummies(datathon['sex'])\n",
        "datathon=pd.concat([datathon,sex_feature],axis=1)\n",
        "\n",
        "age_feature=pd.get_dummies(datathon['age'])\n",
        "datathon=pd.concat([datathon,age_feature],axis=1)\n",
        "\n",
        "# 제외할 column\n",
        "datathon=datathon.drop(['sex','age','Myelocyte','Metamyelo','Band.neut.',\n",
        "                        'Blast','Promyelo','Imm.cell','Imm.lympho','Imm.mono',\n",
        "                        'AtypicalLc','Plas.cell','Other','Normoblast','LUC'],axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcc8252f",
      "metadata": {
        "id": "dcc8252f"
      },
      "outputs": [],
      "source": [
        "## 3. Image 전처리\n",
        "start=time()\n",
        "# 3.1. 대상자:사진 = 1:1 불러오기\n",
        "img_meta=img_meta_raw.sort_values(by=[\"fid\", \"fid_idx\"], ascending=[True, True]).reset_index()\n",
        "\n",
        "# fid_idx가 큰 것 뽑기\n",
        "img_meta=img_meta.drop_duplicates(['fid'], keep='last')\n",
        "\n",
        "img_meta=img_meta.rename(columns={'fid':'id'})\n",
        "img_table=pd.merge(img_meta, datathon, how='inner', on='id')\n",
        "img_table[\"adress\"]=img_table['file_name'].apply(lambda x:\"/save/datathon_cxr_2.0/images/\"+str(x))\n",
        "img_id=img_table.loc[:, 'id']\n",
        "img_adress=img_table.loc[:, \"adress\"]\n",
        "\n",
        "# 3.2. Image size 조정\n",
        "#기준치 설정 : 중앙값\n",
        "start=time()\n",
        "img_y, img_x=[],[]\n",
        "\n",
        "for i in range(len(img_adress)):\n",
        "    img=list(pickle.load(open(img_raw[i], 'rb')).shape)\n",
        "    img_y=img_y+[img[0]]\n",
        "    img_x=img_x+[img[1]]\n",
        "    \n",
        "\n",
        "img_y.sort()\n",
        "img_x.sort()\n",
        "median=int(len(img_y)/2)\n",
        "med_y, med_x=img_y[median], img_x[median]\n",
        "max_y, max_x=int(med_y*0.2), int(med_x*0.2)\n",
        "\n",
        "# 기준치로 size\n",
        "img_arr=np.zeros((len(img_adress), max_y, max_x))\n",
        "for i in range(len(img_adress)):\n",
        "    img=Image.fromarray(pickle.load(open(img_raw[i], 'rb')))\n",
        "    img_s=img.resize((max_x, max_y), Image.LANCZOS)\n",
        "    img_arr[i]=np.array(img_s)\n",
        "print(\"동작 시간 : {} 분\".format(round((time()-start)/60,2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa2cb88",
      "metadata": {
        "scrolled": true,
        "id": "1aa2cb88"
      },
      "outputs": [],
      "source": [
        "## 4. Data split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "img_table=img_table[img_table.columns.difference(['index', 'StD', 'SrD', 'fid_idx', 'file_name', 'adress'])]\n",
        "x = img_table[img_table.columns.difference(['OUTCOME'])]\n",
        "y = img_table[['id','OUTCOME']]\n",
        "\n",
        "# split\n",
        "test_size=0.2\n",
        "\n",
        "def split_image(data):\n",
        "    idx=list(data.index)\n",
        "    idx.sort()\n",
        "    idx_img=np.zeros((len(idx), max_y, max_x))\n",
        "    for i in range(len(idx)):\n",
        "        idx_img[i]=img_arr[idx[i]]\n",
        "    return idx_img\n",
        "\n",
        "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=test_size, random_state=123, stratify=y.loc[:,\"OUTCOME\"])\n",
        "img_train=split_image(y_train)\n",
        "img_test=split_image(y_test)\n",
        "\n",
        "#null값 채우기 : train값의 평균\n",
        "x_train=x_train.fillna(x_train.mean())\n",
        "x_test=x_test.fillna(x_train.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e93f67fa",
      "metadata": {
        "id": "e93f67fa"
      },
      "outputs": [],
      "source": [
        "## 5. Image model\n",
        "## 5.1 model : ResNet50\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Activation, GlobalAveragePooling2D, Flatten\n",
        "from keras.applications.resnet_v2 import ResNet50V2\n",
        "\n",
        "start=time()\n",
        "model=ResNet50V2(include_top=False, weights=None, input_shape=(max_y, max_x, 1), classes=2)\n",
        "x=model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Flatten()(x)\n",
        "x=Dense(64, activation='relu', name='relu')(x)\n",
        "x=Dense(10, activation='softmax', name='softmax')(x)\n",
        "model=Model(model.input, x)\n",
        "print(\"동작 시간 : {} 분\".format(round((time()-start)/60,2)))\n",
        "\n",
        "# Model compile\n",
        "start=time()\n",
        "model.compile(optimizer='adam', # wight, bias를 업데이트 하는 방법 \n",
        "            loss='sparse_categorical_crossentropy', # 오차측정방법\n",
        "            metrics=['accuracy']) # 테스트평가법\n",
        "print(\"동작 시간 : {} 분\".format(round((time()-start)/60,2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "031eb277",
      "metadata": {
        "id": "031eb277"
      },
      "outputs": [],
      "source": [
        "# model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ebe99f5",
      "metadata": {
        "scrolled": true,
        "id": "1ebe99f5"
      },
      "outputs": [],
      "source": [
        "## 5. model - Image \n",
        "## 5.2. run\n",
        "\n",
        "# model fitting\n",
        "start=time()\n",
        "model.fit(img_train, y_train.loc[:,\"OUTCOME\"], epochs=10, batch_size=32, verbose=1)\n",
        "print(\"model fitting 동작 시간 : {} 분\\n\".format(round((time()-start)/60,2)))\n",
        "\n",
        "# model evaluate\n",
        "start=time()\n",
        "loss, acc = model.evaluate(img_test, y_test.loc[:,\"OUTCOME\"], verbose=1)\n",
        "print(\"model evaluate 동작 시간 : {} 분\\n\".format(round((time()-start)/60, 2)))\n",
        "\n",
        "# model predict\n",
        "start=time()\n",
        "af_img_train=model.predict(img_train)  \n",
        "af_img_train=pd.concat([x_train.reset_index(), pd.DataFrame(af_img_train)], axis=1)\n",
        "af_img_train_rmid=af_img_train[af_img_train.columns.difference(['id'])]\n",
        "\n",
        "af_img_test=model.predict(img_test)  \n",
        "af_img_test=pd.concat([x_test.reset_index(), pd.DataFrame(af_img_test)], axis=1)\n",
        "af_img_test_rmid=af_img_test[af_img_test.columns.difference(['id'])]\n",
        "print(\"model predict 동작 시간 : {} 분\\n\".format(round((time()-start)/60, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bba199b4",
      "metadata": {
        "id": "bba199b4"
      },
      "outputs": [],
      "source": [
        "## 6. Final classifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score, roc_auc_score\n",
        "from sklearn import metrics\n",
        "\n",
        "def pred_eval(y_test, y_pred, model):\n",
        "    print(\"Model : \", model)\n",
        "    print('정확도(Accuracy)  : ' , round(accuracy_score(y_test, y_pred), 5))\n",
        "    print('정밀도(Precision) : ' , round(precision_score(y_test, y_pred), 5))\n",
        "    print('재현율(Recall)    : ' , round(recall_score(y_test, y_pred), 5))\n",
        "    print('F1 score         : ' , round(f1_score(y_test, y_pred), 5))\n",
        "    print('AUC              : ' , round(roc_auc_score(y_test, y_pred), 5),\"\\n\")\n",
        "\n",
        "\n",
        "def rf_default(x_train, y_train, x_test, y_test):\n",
        "    start=time()\n",
        "    clf = RandomForestClassifier()\n",
        "    clf.fit(x_train, y_train)\n",
        "    y_pred=clf.predict(x_test)\n",
        "    feature_importance = clf.feature_importances_\n",
        "    pred_eval(y_test, y_pred, \"Random Forest, default\")\n",
        "    print(\"model fit(Random Forest, default) : {} 분\\n\".format(round((time()-start)/60, 2)))\n",
        "    return y_pred, feature_importance\n",
        "\n",
        "def xg_default(x_train, y_train, x_test, y_test):\n",
        "    start=time()\n",
        "    clf = XGBClassifier()\n",
        "    clf.fit(x_train, y_train)\n",
        "    y_pred=clf.predict(x_test)\n",
        "    feature_importance = clf.feature_importances_\n",
        "    pred_eval(y_test, y_pred, \"XGBoost, default\")\n",
        "    print(\"model fit(XGBoost, default) : {} 분\\n\".format(round((time()-start)/60, 2)))\n",
        "    return y_pred, feature_importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95b41a7a",
      "metadata": {
        "scrolled": true,
        "id": "95b41a7a"
      },
      "outputs": [],
      "source": [
        "## 7. Result\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def feature_impo(feature_importance, X_train, model):\n",
        "    feature_imp=np.array(feature_importance)\n",
        "    feature_name=np.array(X_train.columns)\n",
        "    data={\"feature_name\": feature_name, \"feature_importance\":feature_imp}\n",
        "    data=pd.DataFrame(data)\n",
        "    data.sort_values(by=['feature_importance'], ascending=False, inplace=True)\n",
        "    plt.figure(figsize=(10,20))\n",
        "    sns.barplot(x=data['feature_importance'], y=data[\"feature_name\"])\n",
        "    plt.title(model+\" feature importance\")\n",
        "    plt.show()\n",
        "    return \n",
        "\n",
        "def feature_impo_df(feature_importance, X_train):\n",
        "    feature_importance = pd.Series(feature_importance, index=X_train.columns)\n",
        "    feature_top = feature_importance.sort_values(ascending=False)[:len(X_train)]\n",
        "    feature = pd.DataFrame(feature_top.reset_index())\n",
        "    feature.columns = ['feature', 'importance']\n",
        "    return feature\n",
        "\n",
        "#confusion matrix\n",
        "def confu(y_test, y_pred, model):\n",
        "    result = pd.concat([y_test.loc[:,['OUTCOME']].reset_index(drop=True),pd.DataFrame(y_pred,columns=['예측값'])],axis=1)\n",
        "    cm=pd.DataFrame(confusion_matrix(result['OUTCOME'],result['예측값']))\n",
        "    sns.heatmap(cm, annot=True, fmt='g')\n",
        "    plt.title(model+\" Confusion Metrix\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c18cfc0",
      "metadata": {
        "id": "3c18cfc0"
      },
      "outputs": [],
      "source": [
        "## 결과 출력\n",
        "## model result : image+table\n",
        "X_train=af_img_train_rmid\n",
        "Y_train=y_train.loc[:,'OUTCOME']\n",
        "X_test=af_img_test_rmid\n",
        "Y_test=y_test.loc[:, 'OUTCOME']\n",
        "\n",
        "y_pred_rf, feature_importance_rf=rf_default(X_train, Y_train, X_test, Y_test)\n",
        "y_pred_xg, feature_importance_xg=xg_default(X_train, Y_train, X_test, Y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "358e31ce",
      "metadata": {
        "scrolled": false,
        "id": "358e31ce"
      },
      "outputs": [],
      "source": [
        "# feature importance\n",
        "rfimpo=feature_impo(feature_importance_rf, X_test, \"Random Forest\")\n",
        "xgimpo=feature_impo(feature_importance_xg, X_test, \"XGBoost\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92f26d71",
      "metadata": {
        "id": "92f26d71"
      },
      "outputs": [],
      "source": [
        "# feature importance_table\n",
        "feature_impo_df(feature_importance_rf, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e240ff9",
      "metadata": {
        "id": "7e240ff9"
      },
      "outputs": [],
      "source": [
        "# feature importance_table\n",
        "feature_impo_df(feature_importance_xg, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c140c8e",
      "metadata": {
        "id": "1c140c8e"
      },
      "outputs": [],
      "source": [
        "# confusion matrix\n",
        "confu(DataFrame(Y_test), y_pred_rf, \"Random Forest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d51838d4",
      "metadata": {
        "id": "d51838d4"
      },
      "outputs": [],
      "source": [
        "# confusion matrix\n",
        "confu(DataFrame(Y_test), y_pred_xg, \"XGBoost\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}